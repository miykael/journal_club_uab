{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nibabel\n",
    "\n",
    "Nibabel is a low-level Python library that gives access to a variety of imaging formats, with a particular focus on providing a common interface to the various **volumetric** formats produced by scanners and used in common neuroimaging toolkits.\n",
    "\n",
    " - NIfTI-1\n",
    " - NIfTI-2\n",
    " - SPM Analyze\n",
    " - FreeSurfer .mgh/.mgz files\n",
    " - Philips PAR/REC\n",
    " - Siemens ECAT\n",
    " - DICOM (limited support)\n",
    "\n",
    "It also supports **surface** file formats\n",
    "\n",
    " - GIFTI\n",
    " - FreeSurfer surfaces, labels and annotations\n",
    "\n",
    "**Connectivity**\n",
    "\n",
    " - CIFTI-2\n",
    "\n",
    "**Tractocgraphy**\n",
    "\n",
    " - TrackViz .trk files\n",
    "\n",
    "And a number of related formats.\n",
    "\n",
    "**Note:** Almost all of these can be loaded through the `nibabel.load` interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image settings\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import nibabel as nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and inspecting images in `nibabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a functional image of subject 01\n",
    "img = nb.load('/data/ds000114/sub-02/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the header of this file\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data-affine-header structure is common to volumetric formats in nibabel, though the details of the header will vary from format to format.\n",
    "\n",
    "### Access specific parameters\n",
    "\n",
    "If you're interested in specific parameters, you can access them very easily, as the following examples show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = img.get_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = img.affine\n",
    "affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = img.header['pixdim']\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the `'pixdim'` above contains the voxel resolution  (`3.125., 3.125, 4.2`), as well as the TR (`2.`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The data is a simple numpy array. It has a shape, it can be sliced and generally manipulated as you would any array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[:, :, data.shape[2] // 2, 0].T, cmap='Greys_r')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "t1 = nb.load('/data/ds000114/sub-02/ses-test/anat/sub-02_ses-test_T1w.nii.gz')\n",
    "data = t1.get_data()\n",
    "plt.imshow(data[:, :, data.shape[2] // 2].T, cmap='Greys_r')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and saving images\n",
    "\n",
    "Suppose we want to save space by rescaling our image to a smaller datatype, such as an unsigned byte. To do this, we first need to take the data, change it's datatype and save this new data in a new NIfTI image with the same header and affine as the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to load the image and get the data\n",
    "img = nb.load('/data/ds000114/sub-02/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz')\n",
    "data = img.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we force the values to be between 0 and 255\n",
    "# and change the datatype to unsigned 8-bit\n",
    "rescaled = ((data - data.min()) * 255. / (data.max() - data.min())).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can save the changed data into a new NIfTI file\n",
    "new_img = nb.Nifti1Image(rescaled, affine=img.affine, header=img.header)\n",
    "nb.save(new_img, '/tmp/rescaled_image.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nilearn\n",
    "\n",
    "[Nilearn](http://nilearn.github.io/index.html) labels itself as: *A Python module for fast and easy statistical learning on NeuroImaging data. It leverages the scikit-learn Python toolbox for multivariate statistics with applications such as predictive modelling, classification, decoding, or connectivity analysis.*\n",
    "\n",
    "But it's much more than that. It is also an excellent library to **manipulate** (e.g. resample images, smooth images, ROI extraction, etc.) and **visulaize** your neuroimages.\n",
    "\n",
    "So let's visit all three of those domains:\n",
    "\n",
    "1. Image manipulation\n",
    "2. Image visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image settings\n",
    "from nilearn import plotting\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial we will be using the anatomical and functional image of subject 1. So let's load them already here that we have a quicker access later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image as nli\n",
    "t1 = nli.load_img('/data/ds000114/sub-02/ses-test/anat/sub-02_ses-test_T1w.nii.gz')\n",
    "bold = nli.load_img('/data/ds000114/sub-02/ses-test/func/sub-02_ses-test_task-fingerfootlips_bold.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the bold image didn't reach steady-state at the beginning of the image, let's cut of the first 5 volumes, to be sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bold = bold.slicer[..., 5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image manipulation with `nilearn`\n",
    "\n",
    "### Let's create a mean image\n",
    "\n",
    "If you use nibabel to compute the mean image, you first need to load the img, get the data and then compute the mean thereof. With nilearn you can do all this in just one line with `mean image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image as nli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nli.mean_img(bold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! What else can we do with the `image` module?  \n",
    "Let's see..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample image to a template\n",
    "Using `resample_to_img`, we can resample one image to have the same dimensions as another one. For example, let's resample an anatomical T1 image to the computed mean image above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = nli.mean_img(bold)\n",
    "print([mean.shape, t1.shape])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's resample the t1 image to the mean image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_t1 = nli.resample_to_img(t1, mean)\n",
    "resampled_t1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image size of the resampled t1 image seems to be right. But what does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "plotting.plot_anat(t1, title='original t1', display_mode='z', dim=-1,\n",
    "                   cut_coords=[-20, -10, 0, 10, 20, 30])\n",
    "plotting.plot_anat(resampled_t1, title='resampled t1', display_mode='z', dim=-1,\n",
    "                   cut_coords=[-20, -10, 0, 10, 20, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth an image\n",
    "Using `smooth_img`, we can very quickly smooth any kind of MRI image. Let's for example take the mean image from above and smooth it with different FWHM values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fwhm in range(1, 12, 5):\n",
    "    smoothed_img = nli.smooth_img(mean, fwhm)\n",
    "    plotting.plot_epi(smoothed_img, title=\"Smoothing %imm\" % fwhm,\n",
    "                     display_mode='ortho', cmap='magma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask an image and extract an average signal of a region\n",
    "\n",
    "Thanks to nibabel and nilearn you can consider your images just a special kind of a numpy array. Which means that you have all the liberties that you are used to.\n",
    "\n",
    "For example, let's take a functional image, (1) create the mean image thereof, than we (2) threshold it to only keep the voxels that have a value that is higher than 95% of all voxels. Of this thresholded image, we only (3) keep those regions that are bigger than 1000mm^3. And finally, we (4) binarize those regions to create a mask image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So first, we load again a functional image and compute the mean thereof."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = nli.mean_img(bold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `threshold_img` to only keep voxels that have a value that is higher than 95% of all voxels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = nli.threshold_img(mean, threshold='95%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's only keep those voxels that are in regions/clusters that are bigger than 1000mm^3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_size = np.prod(thr.header['pixdim'][1:4])  # Size of 1 voxel in mm^3\n",
    "voxel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the mask that only keeps those big clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.regions import connected_regions\n",
    "cluster = connected_regions(thr, min_region_size=1000. / voxel_size, smoothing_fwhm=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, let's binarize this cluster file to create a mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = nli.math_img('np.mean(img,axis=3) > 0', img=cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us investigate this mask by visualizing it on the subject specific anatomy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import plot_roi\n",
    "plotting.plot_roi(mask, bg_img=t1, display_mode='ortho', dim=-.5, cmap='magma_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is now to take this mask, apply it to the original functional image and extract the mean of the temporal signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply mask to original functional image\n",
    "from nilearn.masking import apply_mask\n",
    "\n",
    "all_timecourses = apply_mask(bold, mask)\n",
    "all_timecourses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can bring the timecourses (or masked data) back into the original 3D/4D space with `unmask`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.masking import unmask\n",
    "img_timecourse = unmask(all_timecourses, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute mean trace of all extractet timecourses and plot the mean signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_timecourse = all_timecourses.mean(axis=1)\n",
    "plt.plot(mean_timecourse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image visualization with `nilearn`\n",
    "\n",
    "Above, we've already seen some ways on how to visualize brain images with `nilearn`. And there are many more. To keep this notebook short, we will only take a look at some of them. For a complete list, see [nilearn's plotting section](http://nilearn.github.io/plotting/index.html).\n",
    "\n",
    "**Note:** In most of the `nilearn`'s plotting functions, you can specify the value `output_file=example.png'`, to save the figure directly to a file."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
